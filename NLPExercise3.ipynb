{"cells":[{"cell_type":"markdown","metadata":{"id":"ZXDm73U3lm4o"},"source":["## Word Embeddings for Sentiment Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qXHXbDxukUQA"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1662212755481,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"},"user_tz":240},"id":"-CbR1IIql99h","outputId":"da0dc89a-6f06-4d3d-e520-32045af375cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.8.2\n"]}],"source":["print(tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"E-RX5SrzmfFu"},"source":["Downloading the TensorFlow imdb_review dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EWj1FXkumc6e"},"outputs":[],"source":["data,info = tfds.load(\"imdb_reviews\",with_info=True,as_supervised=True)"]},{"cell_type":"markdown","metadata":{"id":"aLTJHNWQm5-y"},"source":["Segregate training and testing tests"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6FWx_ozm2CA"},"outputs":[],"source":["train_data,test_data = data['train'], data['test']\n","\n","train_sentences = []\n","test_sentences = []\n","\n","train_labels = []\n","test_labels = []\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"vs_xKCOHnTZ5"},"outputs":[],"source":["from dataclasses import dataclass\n","#Iterate over the train data to extract sentences and labels\n","for sent,label in train_data:\n","  train_sentences.append(str(sent.numpy().decode('utf8')))\n","  train_labels.append(label.numpy())\n","\n","from dataclasses import test_data\n","#Iterate over the train data to extract sentences and labels\n","for sent,label in train_data:\n","  test_sentences.append(str(sent.numpy().decode('utf8')))\n","  test_labels.append(label.numpy())\n"]},{"cell_type":"markdown","source":["Data Perparation - setting up the tokenizer"],"metadata":{"id":"ZF6f_nUQzhUO"}},{"cell_type":"code","execution_count":15,"metadata":{"id":"qaxnlVcsnqpq","executionInfo":{"status":"ok","timestamp":1662216260368,"user_tz":240,"elapsed":136,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"outputs":[],"source":["#define the parameter for the tokenizing and padding\n","vocab_size = 10000\n","embedding_dim = 16\n","max_length = 150\n","trunc_type = \"post\"\n","oov_tok = \"<oov>\""]},{"cell_type":"code","source":["tokenizer = Tokenizer(num_words=vocab_size,oov_token=oov_tok)\n","tokenizer.fit_on_texts(train_sentences)\n","word_index = tokenizer.index_word\n","\n","#Training sequences and labels\n","train_seqs = tokenizer.texts_to_sequences(train_sentences)\n","train_padded = pad_sequences(train_seqs,maxlen=max_length,truncating=trunc_type)\n","\n","#Test sequences and lables\n","test_seq = tokenizer.texts_to_sequences(test_sentences)\n","test_padded = pad_sequences(test_seq,maxlen=max_length)\n"],"metadata":{"id":"wUoHFvI8zZv3","executionInfo":{"status":"ok","timestamp":1662216924189,"user_tz":240,"elapsed":33475,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"glVsdVH10LGa"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOYsjs6GwRXcvkhog7uWXpr"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}